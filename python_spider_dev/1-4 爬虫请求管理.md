### 爬虫请求管理

### 第一章 请求管理

#### 1.1 请求管理业务

> - 请求去重管理: 防止重复请求  --> 如何判断是"重复"的
> - 请求缓冲管理: 临时存储请求
> - 请求调度管理: 派遣并控制请求调度顺序, 请求优先级管理

#### 1.2 请求去重管理

> - 请求去重判断依据		
>   - 请求方法
>   - 请求地址
>   - URL查询参数
>   - 请求体
> - 去重方案
>   - 基于信息摘要算法求指纹的去重
>   - 基于布隆过滤器的去重
> - 请求数据处理
>   - 统一大小写(URL, METHOD)
>   - URL查询参数排序 (query)
>   - 请求体排序 (data)

#### 1.3 codes

```python
# 实现请求去重的逻辑

class RequestFilter(object):
    
    def __init__(self, filter_obj):
        self.filter_obj = filter_obj
    
    def is_exists(self, request_obj):
        """判断请求是否已经处理过"""
        data = self.get_request_filter_data(request_obj)
        self.filter_obj.is_exists(data)
    
    def mark_request(self, request_obj):
        """标记已经处理过的请求对象"""
        data = self.get_request_filter_data(request_obj)
        self.filter_obj.save(data)
    
    def get_request_filter_data(self, request_obj):
        """根据请求对象, 处理他的关于去重的部分, 转换为字符串, 然后进行去重处理"""
        # URL:  https://www.baidu.com/s?wd=python&a=100&b=200
        # URL:  https://www.baidu.com/s?wd=python&a=100&b=200
        # 把协议部分和域名部分进行大小写统一, 其他的保留原始大小写格式
        # 对查询参数进行简单的排序
        # 其中一个解决思路: [("wd", "python"), ("a", 100), ("b", 200)]  再用 sort() 排序
        url = request_obj.url
        # method  .upper()
        method = request_obj.method
        # query: sorted({}.items())    [()]   str([])
        # 考虑: 把url中的请求查询参数和query里的进行合并
        query = request_obj.query
        # body: str(sorted({}.items()))
        body = request_obj.body
        
        data = ""
        return data
```

> import urllib.parse      py3 内置模块;
>
> import   w3lib.url      兼容 py2 和 py3  , 但是要  pip install 

