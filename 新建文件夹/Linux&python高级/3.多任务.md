## 多任务--线程

### 1.相关概念

> 多任务: *操作系统可以同时运行多个任务*

#### 并发：
- 指的是任务数大于cpu核数，通过操作系统的各种任务调度算法，实现用多个任务“一起”执行（实际上总有一些任务不在执行，因为切换任务的速度相当快，看上去一起执行而已）
#### 并行：
- 指的是任务数小于等于cpu核数，即任务真的是一起执行的

#### 同步

- 同步就是协同步调，按预定的先后次序进行运行

#### 异步

- 略

#### 互斥锁

- 当多个线程几乎同时修改某一个共享数据的时候，需要进行同步控制
- 线程同步能够保证多个线程安全访问竞争资源，最简单的同步机制是引入互斥锁。
- 互斥锁为资源引入一个状态：锁定/非锁定
- 某个线程要更改共享数据时，先将其锁定，此时资源的状态为“锁定”，其他线程不能更改；直到该线程释放资源，将资源的状态变成“非锁定”，其他的线程才能再次锁定该资源。互斥锁保证了每次只有一个线程进行写入操作，从而保证了多线程情况下数据的正确性。



### 2.线程(Threading模块)

> - python的thread模块是比较底层的模块
> - threading模块是对thread做了一些包装的，可以更加方便的被使用



```python
import threading
import time


def func1():
    for i in range(5):
        print("这是一个线程测试函数func1")
        time.sleep(1)


def func2():
    for i in range(5):
        print("这是一个线程测试函数func2")
        time.sleep(1)


if __name__ == '__main__':
    print("-------主线程执行开始:{}-----------------".format(time.ctime()))
    t1 = threading.Thread(target=func1)
    t2 = threading.Thread(target=func2)
    t1.start()  #启动线程，即让线程开始执行
    t2.start()

    time.sleep(5)
    print("-------主线程执行结束:{}-----------------".format(time.ctime()))


########################################################
"""
笔记：
1.使用多线程并发的操作，花费时间要短很多
2.当调用start()时，才会真正的创建线程，并且开始执行
3.主线程会等待所有的子线程结束后才结束
4.threading.enumerate()  ： 是一个保存了 当前模块所有 线程的序列； 
"""
```



```python
import threading
import time


class MyThread(threading.Thread):
    """自定义的多线程类"""
    def run(self):
        for i in range(5):
            time.sleep(1)
            msg = "I'm " + self.name + " > " + str(i)  # name属性中保存的是当前线程的名字
            print(msg)
    
    def other_func(self):
        """在这里定义其他方法"""
        pass


def main():
    for i in range(5):
        t = MyThread()
        t.start()


if __name__ == '__main__':
    main()


########################################################
"""
笔记：
1.使用多线程并发的操作，花费时间要短很多
2.当调用start()时，才会真正的创建线程，并且开始执行

3.主线程会等待所有的子线程结束后才结束

4.一般工程中更多的是封装 MyThread(threading.Thread) , 重写 run() 方法来实现 多线程; 当执行 线程实例.start() 时，python解释器自动去实现每个线程实例都去执行 run()
    - 当线程的run()方法结束时该线程完成

5.多线程的执行顺序是不确定的。
    - 无法控制线程调度程序，但可以通过别的方式来影响线程调度的方式

6.每一个线程可以指定名字， 如果不指定默认是： Thread-N


"""
```

> ​	多线程程序的执行顺序是不确定的。当执行到sleep语句时，线程将被阻塞（Blocked），到sleep结束后，线程进入就绪（Runnable）状态，等待调度。而线程调度将自行选择一个线程执行。上面的代码中只能保证每个线程都运行完整个run函数，但是线程的启动顺序、run函数中每次循环的执行顺序都不能确定。

### 3.线程核心概念

#### 3.1 (主|子)线程 生命周期

- 子线程: 
  - 调用 `Thread()`:  实例化的时候, 不会创建  子线程
  - 子线程 创建线程 并 开始执行: start()  ,  (内部会继续去调用 `run()`方法)
  - 当 target 的目标函数运行结束的时候, 子线程生命周期结束

- 主线程
  - 主线程最后结束
  - 主线程如果意外死掉, 子线程就死掉了

#### 3.2 共享全局变量及问题

- 在一个进程内的所有线程共享全局变量，很方便在多个线程间共享数据
- 缺点就是，线程是对全局变量随意遂改可能造成多线程之间对全局变量的混乱（即线程非安全）

- 如果多个线程同时对同一个全局变量操作，会出现资源竞争问题，从而数据结果会不正确

```python
import threading
import time
import sys


g_num = 0
# count = 100000
count = int(sys.argv[1])

def _sum_1(count):
    global g_num
    for i in range(count):
        g_num += 1
        # time.sleep(0.0001)


def _sum_2(count):
    global g_num
    for i in range(count):
        g_num += 1
        # time.sleep(0.0001)


if __name__ == '__main__':
    t1 = threading.Thread(target=_sum_1, args=(count, ))
    t2 = threading.Thread(target=_sum_2, args=(count, ))

    t1.start()
    t2.start()

    while len(threading.enumerate()) != 1:
        time.sleep(1)

    print("主函数执行结束: {}".format(time.ctime()))
    print("当前g_num的值：{}".format(g_num))
```



#### 3.3 上锁解锁过程

- 当一个线程调用锁的acquire()方法获得锁时，锁就进入“locked”状态。
- 每次只有一个线程可以获得锁。如果此时另一个线程试图获得这个锁，该线程就会变为“blocked”状态，称为“阻塞”，直到拥有锁的线程调用锁的release()方法释放锁之后，锁进入“unlocked”状态。
- 线程调度程序从处于同步阻塞状态的线程中选择一个来获得锁，并使得该线程进入运行（running）状态。



```python
import threading
import time
import sys


g_num = 0
# count = 100000
count = int(sys.argv[1])

# 创建锁
mutex = threading.Lock()
# # 锁定
# mutex.acquire()
# # 释放
# mutex.release()


def _sum_1(count):
    global g_num
    for i in range(count):
        mutex.acquire()  # 上锁
        g_num += 1
        mutex.release()  # 解锁

    print("---—_sun_1---g_num=%d" % g_num)


def _sum_2(count):
    global g_num
    for i in range(count):
        mutex.acquire()  # 上锁
        g_num += 1
        mutex.release()  # 解锁

    print("---—_sun_2---g_num=%d" % g_num)


if __name__ == '__main__':
    t1 = threading.Thread(target=_sum_1, args=(count, ))
    t2 = threading.Thread(target=_sum_2, args=(count, ))

    t1.start()
    t2.start()

    while len(threading.enumerate()) != 1:
        time.sleep(1)

    print("当前g_num的值：{}".format(g_num))
```



#### 3.4 锁的优劣

锁的好处：

- 确保了某段关键代码只能由一个线程从头到尾完整地执行

锁的坏处：

- 阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了
- 由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁
  - 死锁: 在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成死锁。

#### 3.5 避免死锁

- 程序设计时要尽量避免（银行家算法）
- 添加超时时间等

```python
import threading
import time
import sys


g_num = 0
# count = 100000
try:
    count = int(sys.argv[1])
except Exception as e:
    count = 100000

class MyThread1(threading.Thread):
    def run(self):
        # 对mutexA上锁
        # mutexA.acquire()
        mutexA.acquire()

        # mutexA上锁后，延时1秒，等待另外那个线程 把mutexB上锁
        print(self.name+'----do1---up----')
        time.sleep(1)

        # 此时会堵塞，因为这个mutexB已经被另外的线程抢先上锁了
        mutexB.acquire()
        print(self.name+'----do1---down----')
        mutexB.release()

        # 对mutexA解锁
        mutexA.release()


class MyThread2(threading.Thread):
    def run(self):
        # 对mutexB上锁
        mutexB.acquire()

        # mutexB上锁后，延时1秒，等待另外那个线程 把mutexA上锁
        print(self.name+'----do2---up----')
        time.sleep(1)

        # 此时会堵塞，因为这个mutexA已经被另外的线程抢先上锁了
        mutexA.acquire()
        print(self.name+'----do2---down----')
        mutexA.release()

        # 对mutexB解锁
        mutexB.release()


mutexA = threading.Lock()
mutexB = threading.Lock()


if __name__ == '__main__':
    t1 = MyThread1()
    t2 = MyThread2()
    t1.start()
    t2.start()

    while len(threading.enumerate()) != 1:
        time.sleep(1)

    print("当前g_num的值：{}".format(g_num))
```













## 多任务 -- 进程

### 1.相关概念和结论

1.进程比线程要稳定

- 主进程死掉,子进程可以存活;  
- 子线程死掉 , 子线程一般也死掉.

**2.多线程 和 多进程 中 子线程或子进程 彼此的执行顺序都是不确定的. 这是他们的共同点.**

3.获取进程 pid , 使用python的 `os` 模块, `os.getpid()` 或 `os.getppid()`

4.**多进程 之间 不共享全局变量**

5.进程是资源分配的最小单位, 线程是资源调度的单位(具体去执行任务的单位). 所以一定是先有进程再有线程

6.举例: 

> 手机中两个播放器, 每个播放器都在同时的下载和播放 音乐. 
>
> - 每个播放器就相当于运行起来的 进程;
> - 而下载和播放同时进行 相当于 进程中的 两个线程.

7.进程间通信方式:

- socket   网络通信
- 文件    写 读
- 发现上述都要经过内存, 那么如果有一种东西, 可以支持同时从内存存取 数据, 那么效率会很高, 这就是 `Queue` 队列
  - 仅限于本地
  - 队列: `FIFO`     :   目的:  `解耦`
  - 栈 : `LIFO`

- `redis` 分布式 队列, 可以跨机

8.进程池, 自动管理进程

- 在有任务需要用到多个进程的时候, 才开始创建多个进程.
- 添加任务超过进程池的最大进程数的时候, 进程池会保存那些没有开启的进程, 当进程池有空闲的时候开始继续开启新的进程. 即不会堵塞.
- 进程池可以通过  `close()` 关闭
- 注意点:  `join()` 方法不再对单个进程产生作用. 所有必须  `pool.join()` 表示当进程池中所有进程全部执行完成才主进程结束. 如果只是按照 之前的`p.join()` 主进程结束, 则进程池中的 进程也会结束.  

9.进程状态

- 工作中，任务数往往大于cpu的核数，即一定有一些任务正在执行，而另外一些任务在等待cpu进行执行，因此导致了有了不同的状态

![进程状态](imgs/进程状态.png)

- 就绪态：运行的条件都已经满足，正在等在cpu执行
- 执行态：cpu正在执行其功能
- 等待态：等待某些条件满足，例如一个程序sleep了，此时就处于等待态

**10.进程 线程 对比**

- 定义
  - ==进程是系统进行资源分配和调度的一个独立单位.==
  - 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.
- 区别
  - 一个程序至少有一个进程,一个进程至少有一个线程.
  - 线程的划分尺度小于进程(资源比进程少)，使得多线程程序的并发性高。
  - 进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率
  - 线程不能够独立执行，必须依存在进程中
  - 可以将进程理解为工厂中的一条流水线，而其中的线程就是这个流水线上的工人
- 线程和进程在使用上各有优缺点：
  - 线程执行开销小，但不利于资源的管理和保护；而进程正相反。

**11.注意: 子进程如果出现异常, 不会正常完成任务, 也不会提示.**

### 2.代码

#### 2.1 跨平台: `multiprocessing` 模块

```python
# -*- coding:utf-8 -*-
from multiprocessing import Process
import os
import time

def run_proc():
    """子进程要执行的代码"""
    print('子进程运行中，pid=%d...' % os.getpid())  # os.getpid获取当前进程的进程号
    print('子进程将要结束...')

if __name__ == '__main__':
    print('父进程pid: %d' % os.getpid())  # os.getpid获取当前进程的进程号
    p = Process(target=run_proc)
    p.start()
```

**Process([group [, target [, name [, args [, kwargs]]]]])**

- **target：如果传递了函数的引用，可以任务这个子进程就执行这里的代码**
- **args：给target指定的函数传递的参数，以元组的方式传递**
- **kwargs：给target指定的函数传递命名参数**
- **name：给进程设定一个名字，可以不设定**
- **group：指定进程组，大多数情况下用不到**

**Process创建的实例对象的常用方法：**

- **start()：启动子进程实例（创建子进程）**
- **is_alive()：判断进程子进程是否还在活着**
- **join([timeout])：是否等待子进程执行结束，或等待多少秒**
- **terminate()：不管任务是否完成，立即终止子进程**

**Process创建的实例对象的常用属性：**

- **name：当前进程的别名，默认为Process-N，N为从1开始递增的整数**
- **pid：当前进程的pid（进程号）**



#### 2.2 进程间不共享全局变量

(写时拷贝)

```python
# -*- coding:utf-8 -*-
from multiprocessing import Process
import os
import time

nums = [11, 22]

def work1():
    """子进程要执行的代码"""
    print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))
    for i in range(3):
        nums.append(i)
        time.sleep(1)
        print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))

def work2():
    """子进程要执行的代码"""
    print("in process2 pid=%d ,nums=%s" % (os.getpid(), nums))

if __name__ == '__main__':
    p1 = Process(target=work1)
    p1.start()
    p1.join()

    p2 = Process(target=work2)
    p2.start()
```

#### 2.3 进程间通信 -- Queue(消息队列程序)

```python
import multiprocessing
import random
import time


def download_data(q):
    for i in [10, 11, 12, 15]:
        if not q.full():
            q.put(i)
        time.sleep(random.random())


def analysis_data(q):
    container = []
    while True:
        if not q.empty():
            container.append(q.get())
            time.sleep(random.random())
        else:
            break
    print("模拟数据处理: %s" % container)


if __name__ == '__main__':
    # 1.父进程创建任务队列Queue, 并将引用传递给各个子进程
    q = multiprocessing.Queue(3)  # 参数3表示队列饱和状态下最多存入的数据， 如果不传递参数或者参数为负数，那么则存入数据无限制， 以内存上限为限制
    p1 = multiprocessing.Process(target=download_data, args=(q, ))
    p2 = multiprocessing.Process(target=analysis_data, args=(q, ))
    p1.start()
    p2.start()

    p1.join()
    p2.join()
    print("结束...")
```

#### 2.4 进程池

```python
# *-* coding:utf8 *-*
from multiprocessing import Pool
import random
import time
import os


def worker(msg):
    t_start = time.time()
    print("%s 开始执行， 进程号 %d" % (msg, os.getpid()))
    time.sleep(random.random() * 2)
    t_stop = time.time()
    print(msg, "执行完毕，耗时%0.2f" % (t_stop - t_start))


if __name__ == '__main__':
    # 1.创建进程池
    po = Pool(3)  # 当有任务的时候， 才开始创建进程池， 然后同时开始执行3个进程
    for i in range(10):
        # Pool().apply_async(要调用的目标,(传递给目标的参数元祖,))
        po.apply_async(worker, (i, ))

    print("--------start--------------")
    po.close()  # 关闭进程池， 关闭后 po 不再接收新的请求
    po.join()  # 等待po中所有的子进程执行完成， 必须放在 close() 方法之后
    print("--------end--------------")


########################################################
"""
笔记：
1.po = Pool(3)  # 当添加任务任务 apply_async 的时候， 才开始创建进程池， 然后同时开始执行3个进程
 - 在执行po = Pool(3)的时候 并为创建 进程池
 - apply_async 才开始真正的调度和执行多进程。
2.注意事项： 不同于前面的主进程会等子进程全部执行结束之后才会结束； 由Poll()创建的多进程， 主进程不会等待， 所有必须要 po.join()
3.po.close()  # 关闭进程池， 关闭后 po 不再接收新的请求
4.po.join()  # 等待po中所有的子进程执行完成， 必须放在 close() 方法之后

"""

# 下面是执行结果, 显然是重复利用进程(号)的:
--------start--------------
0 开始执行， 进程号 58241
1 开始执行， 进程号 58242
2 开始执行， 进程号 58243
1 执行完毕，耗时0.42
3 开始执行， 进程号 58242
3 执行完毕，耗时0.01
4 开始执行， 进程号 58242
4 执行完毕，耗时0.80
5 开始执行， 进程号 58242
2 执行完毕，耗时1.26
6 开始执行， 进程号 58243
0 执行完毕，耗时1.44
7 开始执行， 进程号 58241
6 执行完毕，耗时0.97
8 开始执行， 进程号 58243
5 执行完毕，耗时1.52
9 开始执行， 进程号 58242
8 执行完毕，耗时0.65
7 执行完毕，耗时1.69
9 执行完毕，耗时1.88
--------end--------------
```

**multiprocessing.Pool常用函数解析：**

- **apply_async(func[, args[, kwds]]) ：使用非阻塞方式调用func（并行执行，堵塞方式必须等待上一个进程退出才能执行下一个进程），args为传递给func的参数列表，kwds为传递给func的关键字参数列表；**
- **close()：关闭Pool，使其不再接受新的任务；**
- **terminate()：不管任务是否完成，立即终止；**
- **join()：主进程阻塞，等待子进程的退出， 必须在close或terminate之后使用；**



#### 2.5 进程池中的 Queue

如果要使用Pool创建进程，就需要使用multiprocessing.Manager()中的Queue()，而不是multiprocessing.Queue()，否则会得到一条如下的错误信息：

`RuntimeError: Queue objects should only be shared between processes through inheritance.`

```python
# -*- coding:utf-8 -*-

# 修改import中的Queue为Manager
from multiprocessing import Manager,Pool
import os,time,random

def reader(q):
    print("reader启动(%s),父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in range(q.qsize()):
        print("reader从Queue获取到消息：%s" % q.get(True))

def writer(q):
    print("writer启动(%s),父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in "itcast":
        q.put(i)

if __name__=="__main__":
    print("(%s) start" % os.getpid())
    q = Manager().Queue()  # 使用Manager中的Queue
    po = Pool()
    po.apply_async(writer, (q,))

    time.sleep(1)  # 先让上面的任务向Queue存入数据，然后再让下面的任务开始从中取数据

    po.apply_async(reader, (q,))
    po.close()
    po.join()
    print("(%s) End" % os.getpid())
```

#### 2.6 案例:文件拷贝

```python
# *-* coding:utf8 *-*

from multiprocessing import Manager, Pool
import os
import time


def handle_copy(queue, file_name, old_folder_name, new_folder_name):
    """处理具体的文件copy"""
    # 注意： 子进程如果出现异常, 不会正常完成任务, 也不会提示.
    # 解决方案： 写程序是一步一步的去实现。从主体到细节
    # print("模拟 从 %s 到 %s 的文件 %s 拷贝" % (old_folder_name, new_folder_name, file_name))

    try:
        with open(old_folder_name + "/" + file_name, 'rb') as f:
            content = f.read()
    except Exception as e:
        print("读取文件失败")
    else:
        with open(new_folder_name + "/" + file_name, 'wb') as f:
            f.write(content)
        # 拷贝结束就将文件名放入队列中
        queue.put(file_name)


def main():
    """主程序"""
    # 1.获取用户要copy的文件夹的名字
    old_folder_name = input("请输入待拷贝的文件夹的名字：")
    if not os.path.isdir(old_folder_name):
        print("待拷贝的文件夹不存在")
        return
    # 2.创建一个新的文件夹
    new_folder_name = old_folder_name + "复件"
    try:
        os.mkdir(new_folder_name)
    except FileExistsError:
        pass

    # 3.查看原文件夹下有那些文件
    file_names = os.listdir(old_folder_name)

    # 4 通过进程池来进行子进程的创建和管理
    po = Pool(10)
    # 5. 增加进程的消息队列, 让子进程向主进程汇报完成copy的文件名
    queue = Manager().Queue()

    for file_name in file_names:
        po.apply_async(handle_copy, args=(queue, file_name, old_folder_name, new_folder_name))
    po.close()
    # po.join()  # 通过下面的 while True 来实现

    # 5.主进程 人性化 的显示进度条
    # 进程间通信： 子进程 和 主进程 间进行通信
    # queue = Manager().Queue()
    all_file_len = len(file_names)
    while True:
        file_name = queue.get()
        # print("已经完成%s的拷贝" % file_name)
        file_names.remove(file_name)
        res = (all_file_len - len(file_names)) / all_file_len * 100
        print("\r当前拷贝进度：%.2f%%" % res, end='')
        if not file_names:
            break
    print()


if __name__ == '__main__':
    main()
    
"""
思想：
1. 程序不是一蹴而就的， 要先设计后开发， 先整体框架再具体的细节， 同时积累开发过程中调试的经验， 边写边调试
"""
```



## 多任务 -- 协程

### 1.迭代器

> 迭代是访问集合元素的一种方式。迭代器是一个可以记住遍历的位置的对象。迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。

#### 1.1 可迭代(遍历)对象

​	我们已经知道可以对list、tuple、str等类型的数据使用for...in...的循环语法从其中依次拿到数据进行使用，我们把这样的过程称为遍历，也叫**迭代**。

#### 1.2 如何判断一个对象是否可以迭代

```python
from collections import Iterable
from collections import Iterator

print("判断classmate是否是可以迭代的对象:", isinstance(classmate, Iterable))
print("判断classmate_iterator是否是迭代器:", isinstance(classmate_iterator, Iterator))
```

#### 1.3 可迭代对象的本质

我们分析对可迭代对象进行迭代使用的过程，发现每迭代一次（即在for...in...中每循环一次）都会返回对象中的下一条数据，一直向后读取数据直到迭代了所有数据后结束。那么，在这个过程中就应该有一个“人”去记录每次访问到了第几条数据，以便每次迭代都可以返回下一条数据。我们把这个能帮助我们进行数据迭代的“人”称为**迭代器(Iterator)**。

- ==可迭代对象的本质就是可以向我们提供一个这样的中间“人”即迭代器帮助我们对其进行迭代遍历使用。==

- 可迭代对象通过`__iter__`方法向我们提供一个迭代器，我们==在迭代一个可迭代对象的时候，实际上就是先获取该对象提供的一个迭代器，然后通过这个迭代器来依次获取对象中的每一个数据.==

- 那么也就是说，一个具备了`__iter__`方法的对象，就是一个可迭代对象。

#### 1.4 iter()函数与next()函数

​	**list、tuple等都是可迭代对象，我们可以通过iter()函数获取这些可迭代对象的迭代器。然后我们可以对获取到的迭代器不断使用next()函数来获取下一条数据。**iter()函数实际上就是调用了可迭代对象的`__iter__`方法。

- **注意，当我们已经迭代完最后一个数据之后，再次调用next()函数会抛出StopIteration的异常，来告诉我们所有数据都已迭代完成，不用再执行next()函数了。**

#### 1.5 如何判断一个对象是否是迭代器

```python
from collections import Iterator

print("判断classmate_iterator是否是迭代器:", isinstance(classmate_iterator, Iterator))
```

#### 1.6 迭代器

​	通过上面的分析，我们已经知道，迭代器是用来帮助我们记录每次迭代访问到的位置，当我们对迭代器使用next()函数的时候，迭代器会向我们返回它所记录位置的下一个位置的数据。实际上，在使用next()函数的时候，调用的就是迭代器对象的`__next__`方法（Python3中是对象的`__next__`方法，Python2中是对象的next()方法）。**所以，我们要想构造一个迭代器，就要实现它的__next__方法**。但这还不够，python要求迭代器本身也是可迭代的，所以我们还要为迭代器实现`__iter__`方法，而`__iter__`方法要返回一个迭代器，迭代器自身正是一个迭代器，所以迭代器的`__iter__`方法返回自身即可。

**一个实现了__iter__方法和__next__方法的对象，就是迭代器。**

- 迭代器一定是可迭代对象;
- 可迭代对象不一定是迭代器;

#### 1.7 for...in...循环的本质

> ​	==**for item in Iterable 循环的本质就是先通过iter()函数获取可迭代对象Iterable的迭代器，然后对获取到的迭代器不断调用next()方法来获取下一个值并将其赋值给item，当遇到StopIteration的异常后循环结束**==

#### 1.8 迭代器的应用场景

- 不用将所有要迭代的数据都一次性缓存下来供后续依次读取，可以节省大量的存储（内存）空间。
- 斐波拉契数列（Fibonacci）

#### 1.9 `list`, `tuple`等工厂函数的本质

- 1.先创建对应的空序列;
- 2.通过 迭代的方式, 依次往序列中添加元素



### 2.生成器

#### 2.1 生成器是一类特殊的迭代器

​	利用迭代器，我们可以在每次迭代获取数据（通过next()方法）时按照特定的规律进行生成。但是我们在实现一个迭代器时，关于当前迭代到的状态需要我们自己记录，进而才能根据当前状态生成下一个数据。

​	为了达到记录当前状态，并配合next()函数进行迭代使用，我们可以采用更简便的语法，即**生成器(generator)。

#### 2.2 创造生成器的方式

##### 2.2.1 把一个列表生成式的 [ ] 改成 ( )

```python
In [15]: L = [ x*2 for x in range(5)]

In [16]: L
Out[16]: [0, 2, 4, 6, 8]

In [17]: G = ( x*2 for x in range(5))

In [18]: G
Out[18]: <generator object <genexpr> at 0x7f626c132db0>
```

- 对于生成器G，我们可以按照迭代器的使用方法来使用，即可以通过next()函数、for循环、list()等方法使用。

##### 2.2.2 法二:  用函数来实现

- 简单来说：**只要在def中有yield关键字的 就称为 生成器**
- 但是用for循环调用generator时，发现拿不到generator的return语句的返回值。如果想要拿到返回值，必须捕获`StopIteration`错误，返回值包含在`StopIteration`的`value`中

```python
def create_num(all_num):
    a, b = 0, 1
    current_num = 0
    while current_num < all_num:
        yield a  # 如果一个函数中有yield语句，那么这个就不在是函数，而是一个生成器的模板
        a, b = b, a+b
        current_num += 1
    return "ok..."

# 如果在调用create_num的时候，发现这个函数中有yield那么此时，不是调用函数，而是创建一个生成器对象
obj = create_num(10)

while True:
    try:
        ret = next(obj)
        print(ret)
    except StopIteration:
        print(StopIteration.value)  # StopIteration 对象有一个属性 value, 可以获取 yield构成的生成器的模板 的return返回值
        break
```

##### 总结:

- 使用了yield关键字的函数不再是函数，而是生成器。（使用了yield的函数就是生成器）
- yield关键字有两点作用：
  - 保存当前运行状态（断点），然后暂停执行，即将生成器（函数）挂起
  - 将yield关键字后面表达式的值作为返回值返回，此时可以理解为起到了return的作用
- 可以使用next()函数让生成器从断点处继续执行，即唤醒生成器（函数）
- `Python3`中的生成器可以使用return返回最终运行的返回值，而`ython2`中的生成器不允许使用return返回一个返回值（即可以使用return从生成器中退出，但return后不能有任何表达式）。

#### 2.3 使用 `send` | `nexit` | `__next__`唤醒 生成器

​	我们除了可以使用next()函数来唤醒生成器继续执行外，还可以使用send()函数来唤醒执行。使用send()函数的一个好处是可以在唤醒的同时向断点处传入一个附加数据。

```python
# *-* coding:utf8 *-*


def create_num(all_num):
    a, b = 0, 1
    current_num = 0
    while current_num < all_num:
        ret = yield a
        print(">>>ret>>>>", ret)
        a, b = b, a+b
        current_num += 1


obj = create_num(10)

# obj.send(None)  # send一般不会放到第一次启动生成器，如果非要这样做 那么传递None

ret = next(obj)  # 唤醒 yield a (等号右边的部分), 然后生成器对象 “暂停”， 并将 a 返回给 24行的ret
print(ret)  # ret = 1

# send里面的数据会 传递给第13行，当做yield a的结果，然后第13行的 ret保存这个结果,,,
# send的结果是下一次调用yield时 yield后面的值
ret = obj.send("hahahha")  # 开始执行 等号左边(即yield a)左边的代码, 将send()内部的参数作为值传递给等号左边的变量ret; 同时 生成器继续向下执行
print(ret)  # ret = 第二次取出来的a，即1

"""
上述代码执行结果：

0
>>>ret>>>> hahahha
1

"""

"""
笔记：
1. next() 等价于 send(None)
- 第一次不能调用 含非None参数的 send() 函数， 否则会报错; 一般第一次都调用 next() 函数
2. 从执行结果推断出结论：
- 1. ret = next(obj)  # 唤醒 yield a (等号右边的部分), 然后生成器对象 “暂停”， 并将 a 返回给 接收next()函数返回值的变量ret
- 2. send里面的数据会传递给yield a 所在行的等号左边的结果，然后 yield a 左边的变量 保存这个结果
- 3. send的结果是下一次调用yield时 yield后面的值
3. 唤醒操作除了 send next 还可以用原生的 __next__() 
"""
```



### 3.协程 -- yield

- 协程，又称微线程，纤程。英文名Coroutine。

#### 3.1 协程定义

​	==协程是python个中另外一种实现多任务的方式==，只不过比线程更小占用更小执行单元（理解为需要的资源）。 为啥说它是一个执行单元，因为它自带CPU上下文。这样只要在合适的时机， 我们可以把一个协程 切换到另一个协程。 只要这个过程中保存或恢复 CPU上下文那么程序还是可以运行的。

​	==通俗的理解：在一个线程中的某个函数，可以在任何地方保存当前函数的一些临时变量等信息，然后切换到另外一个函数中执行，注意不是通过调用函数的方式做到的，并且切换的次数以及什么时候再切换到原来的函数都由开发者自己确定==

#### 3.2 协程和线程差异

​	在实现多任务时, 线程切换从系统层面远不止保存和恢复 CPU上下文这么简单。 操作系统为了程序运行的高效性每个线程都有自己缓存Cache等等数据，操作系统还会帮你做这些数据的恢复操作。 所以线程的切换非常耗性能。但是协程的切换只是单纯的操作CPU的上下文，所以一秒钟切换个上百万次系统都抗的住。

#### 3.3 代码实现简单的协程

```python
import time


def worker_1():
    while True:
        time.sleep(0.1)
        print("----------1------------")
        yield


def worker_2():
    while True:
        time.sleep(0.1)
        print("----------2------------")
        yield


if __name__ == '__main__':
    # 需要自己进行一个管理
    t1 = worker_1()
    t2 = worker_2()
    # 先让t1运行一会，当t1中遇到yield的时候，再返回到24行，然后
    # 执行t2，当它遇到yield的时候，再次切换到t1中
    # 这样t1/t2/t1/t2的交替运行，最终实现了多任务....协程
    while True:
        next(t1)
        next(t2)
```





### 4.协程 greenlet

- 为了更好使用协程来完成多任务，python中的`greenlet模块`对yield封装，从而使得切换任务变的更加简单

- `pip3 install greenlet`

```python
#  *-* coding:utf8 *-*
from greenlet import greenlet
import time


def test1():
    while True:
        print("---A--")
        gr2.switch()
        time.sleep(0.5)


def test2():
    while True:
        print("---B--")
        gr1.switch()
        time.sleep(0.5)


gr1 = greenlet(test1)
gr2 = greenlet(test2)

# 切换到gr1中运行
gr1.switch()
```



### 5.协程 -- `gevent`

#### 5.1 介绍:

- 协程的更高级封装, `greenlet模块` 对 `greenlet模块`进行了进一步的封装, 完成 自动切换
- 原理是当一个greenlet遇到IO(指的是input output 输入输出，比如网络、文件操作等)操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。
- 由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO

#### 5.2 安装和代码运行

- `pip3 install gevent`

```python
#  *-* coding:utf8 *-*
import gevent
import time


def func1(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        # time.sleep(1)
        gevent.sleep(1)


def func2(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        # time.sleep(1)
        gevent.sleep(1)


def func3(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        # time.sleep(1)
        gevent.sleep(1)


g1 = gevent.spawn(func1, 5)
g2 = gevent.spawn(func2, 5)
g3 = gevent.spawn(func3, 5)

g1.join()
g2.join()
g3.join()

"""运行结果如下：
<Greenlet at 0x7fd539f8d548: func1(5)> 0
<Greenlet at 0x7fd539f8d548: func1(5)> 1
<Greenlet at 0x7fd539f8d548: func1(5)> 2
<Greenlet at 0x7fd539f8d548: func1(5)> 3
<Greenlet at 0x7fd539f8d548: func1(5)> 4
<Greenlet at 0x7fd539f8d748: func2(5)> 0
<Greenlet at 0x7fd539f8d748: func2(5)> 1
<Greenlet at 0x7fd539f8d748: func2(5)> 2
<Greenlet at 0x7fd539f8d748: func2(5)> 3
<Greenlet at 0x7fd539f8d748: func2(5)> 4
<Greenlet at 0x7fd539f8d848: func3(5)> 0
<Greenlet at 0x7fd539f8d848: func3(5)> 1
<Greenlet at 0x7fd539f8d848: func3(5)> 2
<Greenlet at 0x7fd539f8d848: func3(5)> 3
<Greenlet at 0x7fd539f8d848: func3(5)> 4

从结果中产生的合理推断：
1. gevent.getcurrent() 结果是对象， 且是 greenlet 的封装
2. 并没有真正的按照多任务执行： 3个greenlet是依次运行而不是交替运行
3. 如果把 三行 join 注释掉， 则控制台没有任何打印。
    - 主进程如果结束， 主线程结束； 主线程结束， 进程必挂。
    - join() 阻塞作用， 等待各个函数执行结束。
4. 尝试：用time模块中的sleep来模拟一个耗时操作, 发现并没有改观。
5. 尝试：用gevent模块中的sleep来模拟一个耗时操作, 终于看到交替执行。
    - 结论： 必须将程序中的耗时操作都切换成 gevent中 对应的方法， 才能实现多任务
6. 继续推断: 针对不同的耗时操作，如果都需要手动去 修改成 gevent 对应的方法显然不现实， 所有有了 ‘打补丁’
    - monkey.patch_all()
    - 同时采用更加简单的方式 完成 “注册”： gevent.joinall([ ])

"""
```

#### 5.3 打补丁

```python
#  *-* coding:utf8 *-*
import gevent
import time
from gevent import  monkey

# 有耗时操作的时候需要
monkey.patch_all()


def func1(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        time.sleep(1)


def func2(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        time.sleep(1)


def func3(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        time.sleep(1)

        
gevent.joinall([
    gevent.spawn(func1, 10),
    gevent.spawn(func2, 10),
    gevent.spawn(func3, 10),
])


"""运行结果如下：
从结果中产生的合理推断：
1. gevent.getcurrent() 结果是对象， 且是 greenlet 的封装
2. 并没有真正的按照多任务执行： 3个greenlet是依次运行而不是交替运行
3. 如果把 三行 join 注释掉， 则控制台没有任何打印。
    - 主进程如果结束， 主线程结束； 主线程结束， 进程必挂。
    - join() 阻塞作用， 等待各个函数执行结束。
4. 尝试：用time模块中的sleep来模拟一个耗时操作, 发现并没有改观。
5. 尝试：用gevent模块中的sleep来模拟一个耗时操作, 终于看到交替执行。
    - 结论： 必须将程序中的耗时操作都切换成 gevent中 对应的方法， 才能实现多任务
6. 继续推断: 针对不同的耗时操作(文件读取和网络)，如果都需要手动去 修改成 gevent 对应的方法显然不现实， 所有有了 ‘打补丁’
    - monkey.patch_all()
    - 同时采用更加简单的方式 完成 “注册”： gevent.joinall([ ])

"""
```





### 6.进程 线程 协程 区别

#### 6.1 请仔细理解如下的通俗描述

- 有一个老板想要开个工厂进行生产某件商品（例如剪子）
- 他需要花一些财力物力制作一条生产线，这个生产线上有很多的器件以及材料这些所有的 为了能够生产剪子而准备的资源称之为：进程
- 只有生产线是不能够进行生产的，所以老板的找个工人来进行生产，这个工人能够利用这些材料最终一步步的将剪子做出来，这个来做事情的工人称之为：线程
- 这个老板为了提高生产率，想到3种办法：
  1. 在这条生产线上多招些工人，一起来做剪子，这样效率是成倍増长，即单进程 多线程方式
  2. 老板发现这条生产线上的工人不是越多越好，因为一条生产线的资源以及材料毕竟有限，所以老板又花了些财力物力购置了另外一条生产线，然后再招些工人这样效率又再一步提高了，即多进程 多线程方式
  3. 老板发现，现在已经有了很多条生产线，并且每条生产线上已经有很多工人了（即程序是多进程的，每个进程中又有多个线程），为了再次提高效率，老板想了个损招，规定：如果某个员工在上班时临时没事或者再等待某些条件（比如等待另一个工人生产完谋道工序 之后他才能再次工作） ，那么这个员工就利用这个时间去做其它的事情，那么也就是说：如果一个线程等待某些条件，可以充分利用这个时间去做其它事情，其实这就是：协程方式

#### 6.2 简单总结

1. 进程是资源分配的单位
2. 线程是操作系统调度的单位
3. 进程切换需要的资源很最大，效率很低
4. 线程切换需要的资源一般，效率一般（当然了在不考虑GIL的情况下）
5. 协程切换任务资源很小，效率高
6. 多进程、多线程根据cpu核数不一样可能是并行的，但是协程是在一个线程中 所以是并发

> - 1.python中要实现多任务,优先考虑 协程,  其次是 线程, 最后是多进程.
> - 2.协程可以充分利用 耗时操作的时候, 切换到其他任务去执行.

### 7.案例: 并发下载器

```python
# *-* coding:utf8 *-*

import gevent
from gevent import monkey
import urllib.request

# 耗时操作
monkey.patch_all()


def my_downloader(url, file_name):
    resp = urllib.request.urlopen(url, )
    content = resp.read()
    with open(file_name, 'wb') as f:
        f.write(content)


def main():
    gevent.joinall([
        gevent.spawn(my_downloader, "https://p0.meituan.net/movie/bb9f75599bfbb2c4cf77ad9abae1b95c1376927.jpg@160w_220h_1e_1c", '1.jpg'),
        gevent.spawn(my_downloader, "https://p0.meituan.net/moviemachine/7b9b0725ab5feae642e1fbba9fbb90fe3702078.jpg@160w_220h_1e_1c", '2.jpg')
    ])


if __name__ == '__main__':
    main()
```



## 其他补充:

- 僵尸进程
- 孤儿进程
- 时间片轮转
- 写时拷贝